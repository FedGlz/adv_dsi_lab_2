{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a594c9c2-0e55-450d-9db2-a289e8330b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d77d8-bbe6-42bc-9424-f90c6bbfb4fb",
   "metadata": {},
   "source": [
    "### Data Cleaning Step for input into training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd74946b-1ba9-4769-9144-a3d3d9ceb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "df = pd.read_csv('../data/raw/2022_train.csv')\n",
    "df_test = pd.read_csv(\"../data/raw/2022_test.csv\")\n",
    "df_test_backup = pd.read_csv(\"../data/raw/2022_test.csv\")\n",
    "\n",
    "# Improve distribution with skew/tails\n",
    "df['MIN2'] = df['MIN']**(1/3)\n",
    "df['AST2'] = df['AST']**(1/3)\n",
    "df['PTS2'] = df['PTS']**(1/3)\n",
    "df['FGM2'] = df['FGM']**(1/3)\n",
    "df['FGA2'] = df['FGA']**(1/3)\n",
    "df['FTM2'] = df['FTM']**(1/3)\n",
    "df['FTA2'] = df['FTA']**(1/3)\n",
    "df['OREB2'] = df['OREB']**(1/3)\n",
    "df['DREB2'] = df['DREB']**(1/3)\n",
    "df['REB2'] = df['REB']**(1/3)\n",
    "df['STL2'] = df['STL']**(1/3)\n",
    "df['TOV2'] = df['TOV']**(1/3)\n",
    "\n",
    "df2 = df.drop(['Id', 'MIN', 'AST', 'PTS', 'FGM', 'FGA', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'STL', 'TOV'], axis = 1)\n",
    "\n",
    "# Upsampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# separate into y and X\n",
    "y = df2.pop('TARGET_5Yrs')\n",
    "X = df2\n",
    "\n",
    "# use SMOTE\n",
    "su = SMOTE(random_state=42)\n",
    "X_smote, y_smote = su.fit_resample(X, y)\n",
    "\n",
    "# Scale the X values for the upsampled and SMOTE sampled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_smote = scaler.fit_transform(X_smote)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xt_smote, Xv_smote, yt_smote, yv_smote = train_test_split(X_smote, y_smote, test_size = 0.25, stratify=y_smote)\n",
    "\n",
    "# complete the cleaning steps on the test data\n",
    "df_test['MIN2'] = df_test['MIN']**(1/3)\n",
    "df_test['AST2'] = df_test['AST']**(1/3)\n",
    "df_test['PTS2'] = df_test['PTS']**(1/3)\n",
    "df_test['FGM2'] = df_test['FGM']**(1/3)\n",
    "df_test['FGA2'] = df_test['FGA']**(1/3)\n",
    "df_test['FTM2'] = df_test['FTM']**(1/3)\n",
    "df_test['FTA2'] = df_test['FTA']**(1/3)\n",
    "df_test['OREB2'] = df_test['OREB']**(1/3)\n",
    "df_test['DREB2'] = df_test['DREB']**(1/3)\n",
    "df_test['REB2'] = df_test['REB']**(1/3)\n",
    "df_test['STL2'] = df_test['STL']**(1/3)\n",
    "df_test['TOV2'] = df_test['TOV']**(1/3)\n",
    "\n",
    "df2_test = df_test.drop(['Id', 'MIN', 'AST', 'PTS', 'FGM', 'FGA', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'STL', 'TOV'], axis = 1)\n",
    "\n",
    "# Run the Standard Scaler on our test features\n",
    "X_test = scaler.fit_transform(df2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a9e49-d6aa-45ac-8c1f-236c216b5c50",
   "metadata": {},
   "source": [
    "### High AUROC XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64be119f-0433-4b40-83da-1056ac8a2070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8941729639683574\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate\n",
    "xgb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, max_depth = 5, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb.fit(Xt_smote, yt_smote)\n",
    "\n",
    "# predict\n",
    "yv_pred6 = xgb.predict(Xv_smote)\n",
    "\n",
    "# print auroc\n",
    "xgb_smote = roc_auc_score(yv_smote, yv_pred6)\n",
    "print(xgb_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ada0be-5709-4469-b3b3-4aafe8639106",
   "metadata": {},
   "source": [
    "### Better XGBoost Model?\n",
    "Perhaps a lower AUROC will generalise better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43d065a-0fd5-4484-b532-81669464d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511244154046888\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with lower tree depth (4), lower learning rate (0.01)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate\n",
    "xgb4 = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.01, max_depth = 4, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb4.fit(Xt_smote, yt_smote)\n",
    "\n",
    "# predict\n",
    "yv_pred8 = xgb4.predict(Xv_smote)\n",
    "\n",
    "# print auroc\n",
    "xgb_smote = roc_auc_score(yv_smote, yv_pred8)\n",
    "print(xgb_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ec3773-8699-452b-93e8-1fc6ab926df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the lower tree depth (4) with lower learning rate (0.01) on whole training set\n",
    "\n",
    "# instatiate\n",
    "xgb5 = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.01, max_depth = 4, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb5.fit(X_smote, y_smote)\n",
    "\n",
    "# predict using scaled test data\n",
    "xgb_train_y_test_5 = xgb5.predict_proba(X_test)\n",
    "probabilities5 = xgb_train_y_test_5[:,1]\n",
    "\n",
    "# create a dataframe and import back the Ids into with each prediction probability\n",
    "xgb_draft_5 = pd.DataFrame({'Id':df_test_backup.Id, 'TARGET_5Yrs':probabilities5})\n",
    "\n",
    "# save to CSV for upload to Kaggle without the index\n",
    "xgb_draft_5.to_csv('../data/external/2022_timwang_week3try5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d76311a2-f412-47b7-9104-55fca0d98c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model into the model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a1f72-5ed4-4e7e-8d0f-b3e6756c7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(xgb5, '../models/xgb5.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
