{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a594c9c2-0e55-450d-9db2-a289e8330b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d77d8-bbe6-42bc-9424-f90c6bbfb4fb",
   "metadata": {},
   "source": [
    "### Data Cleaning Step for input into training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd74946b-1ba9-4769-9144-a3d3d9ceb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "df = pd.read_csv('data/raw/2022_train.csv')\n",
    "df_test = pd.read_csv(\"data/raw/2022_test.csv\")\n",
    "df_test_backup = pd.read_csv(\"data/raw/2022_test.csv\")\n",
    "\n",
    "# Improve distribution with skew/tails\n",
    "df['MIN2'] = df['MIN']**(1/3)\n",
    "df['AST2'] = df['AST']**(1/3)\n",
    "df['PTS2'] = df['PTS']**(1/3)\n",
    "df['FGM2'] = df['FGM']**(1/3)\n",
    "df['FGA2'] = df['FGA']**(1/3)\n",
    "df['FTM2'] = df['FTM']**(1/3)\n",
    "df['FTA2'] = df['FTA']**(1/3)\n",
    "df['OREB2'] = df['OREB']**(1/3)\n",
    "df['DREB2'] = df['DREB']**(1/3)\n",
    "df['REB2'] = df['REB']**(1/3)\n",
    "df['STL2'] = df['STL']**(1/3)\n",
    "df['TOV2'] = df['TOV']**(1/3)\n",
    "\n",
    "df2 = df.drop(['Id', 'MIN', 'AST', 'PTS', 'FGM', 'FGA', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'STL', 'TOV'], axis = 1)\n",
    "\n",
    "# Upsampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# separate into y and X\n",
    "y = df2.pop('TARGET_5Yrs')\n",
    "X = df2\n",
    "\n",
    "# use SMOTE\n",
    "su = SMOTE(random_state=42)\n",
    "X_smote, y_smote = su.fit_resample(X, y)\n",
    "\n",
    "# Scale the X values for the upsampled and SMOTE sampled data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_smote = scaler.fit_transform(X_smote)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xt_smote, Xv_smote, yt_smote, yv_smote = train_test_split(X_smote, y_smote, test_size = 0.25, stratify=y_smote)\n",
    "\n",
    "# complete the cleaning steps on the test data\n",
    "df_test['MIN2'] = df_test['MIN']**(1/3)\n",
    "df_test['AST2'] = df_test['AST']**(1/3)\n",
    "df_test['PTS2'] = df_test['PTS']**(1/3)\n",
    "df_test['FGM2'] = df_test['FGM']**(1/3)\n",
    "df_test['FGA2'] = df_test['FGA']**(1/3)\n",
    "df_test['FTM2'] = df_test['FTM']**(1/3)\n",
    "df_test['FTA2'] = df_test['FTA']**(1/3)\n",
    "df_test['OREB2'] = df_test['OREB']**(1/3)\n",
    "df_test['DREB2'] = df_test['DREB']**(1/3)\n",
    "df_test['REB2'] = df_test['REB']**(1/3)\n",
    "df_test['STL2'] = df_test['STL']**(1/3)\n",
    "df_test['TOV2'] = df_test['TOV']**(1/3)\n",
    "\n",
    "df2_test = df_test.drop(['Id', 'MIN', 'AST', 'PTS', 'FGM', 'FGA', 'FTM', 'FTA', 'OREB', 'DREB', 'REB', 'STL', 'TOV'], axis = 1)\n",
    "\n",
    "# Run the Standard Scaler on our test features\n",
    "X_test = scaler.fit_transform(df2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f2466-d9d6-401c-85d8-1c1f28a86de7",
   "metadata": {},
   "source": [
    "### Save your datat into the processed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b30581b2-f624-42e6-abd8-ba598361f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('data/processed/Xt_smote', Xt_smote)\n",
    "#np.save('data/processed/Xv_smote', Xv_smote)\n",
    "#np.save('data/processed/yt_smote', yt_smote)\n",
    "#np.save('data/processed/yv_smote', yv_smote)\n",
    "#np.save('data/processed/X_test', X_test)\n",
    "\n",
    "from src.data.sets import save_sets\n",
    "\n",
    "save_sets(X_train = Xt_smote, y_train = yt_smote, X_val = Xv_smote, y_val = yv_smote, X_test = X_test)\n",
    "\n",
    "np.save('data/processed/X_smote', X_smote)\n",
    "np.save('data/processed/y_smote', y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d9e0016-9855-4cd5-ade5-ecce23560aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3645     1\n",
      "9693     0\n",
      "10279    0\n",
      "1078     1\n",
      "779      0\n",
      "        ..\n",
      "6921     1\n",
      "778      0\n",
      "3884     1\n",
      "6340     1\n",
      "11243    0\n",
      "Name: TARGET_5Yrs, Length: 10003, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(yt_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a9e49-d6aa-45ac-8c1f-236c216b5c50",
   "metadata": {},
   "source": [
    "### High AUROC XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64be119f-0433-4b40-83da-1056ac8a2070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8914763809827962\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate\n",
    "xgb = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, max_depth = 5, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb.fit(Xt_smote, yt_smote)\n",
    "\n",
    "# predict\n",
    "yv_pred6 = xgb.predict(Xv_smote)\n",
    "\n",
    "# print auroc\n",
    "xgb_smote = roc_auc_score(yv_smote, yv_pred6)\n",
    "print(xgb_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ada0be-5709-4469-b3b3-4aafe8639106",
   "metadata": {},
   "source": [
    "### Better XGBoost Model?\n",
    "Perhaps a lower AUROC will generalise better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43d065a-0fd5-4484-b532-81669464d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7544244748172668\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with lower tree depth (4), lower learning rate (0.01)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate\n",
    "xgb4 = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.01, max_depth = 4, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb4.fit(Xt_smote, yt_smote)\n",
    "\n",
    "# predict\n",
    "yv_pred8 = xgb4.predict(Xv_smote)\n",
    "\n",
    "# print auroc\n",
    "xgb_smote = roc_auc_score(yv_smote, yv_pred8)\n",
    "print(xgb_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ec3773-8699-452b-93e8-1fc6ab926df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the lower tree depth (4) with lower learning rate (0.01) on whole training set\n",
    "\n",
    "# instatiate\n",
    "xgb5 = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.01, max_depth = 4, random_state=42)\n",
    "\n",
    "# train/fit\n",
    "xgb5.fit(X_smote, y_smote)\n",
    "\n",
    "# predict using scaled test data\n",
    "xgb_train_y_test_5 = xgb5.predict_proba(X_test)\n",
    "probabilities5 = xgb_train_y_test_5[:,1]\n",
    "\n",
    "# create a dataframe and import back the Ids into with each prediction probability\n",
    "xgb_draft_5 = pd.DataFrame({'Id':df_test_backup.Id, 'TARGET_5Yrs':probabilities5})\n",
    "\n",
    "# save to CSV for upload to Kaggle without the index\n",
    "xgb_draft_5.to_csv('data/external/2022_timwang_week3try5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d76311a2-f412-47b7-9104-55fca0d98c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Model into the model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7a1f72-5ed4-4e7e-8d0f-b3e6756c7e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgb5.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(xgb5, 'models/xgb5.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6a4128e-ce58-4b76-963b-e1da242a4c1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GradientBoostingClassifier.__init__() got an unexpected keyword argument 'min_child_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# instantiate\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m xgb6 \u001b[38;5;241m=\u001b[39m \u001b[43mGradientBoostingClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_child_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# train/fit\u001b[39;00m\n\u001b[1;32m      8\u001b[0m xg64\u001b[38;5;241m.\u001b[39mfit(Xt_smote, yt_smote)\n",
      "\u001b[0;31mTypeError\u001b[0m: GradientBoostingClassifier.__init__() got an unexpected keyword argument 'min_child_weight'"
     ]
    }
   ],
   "source": [
    "# Even more punishment for the XGB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate\n",
    "xgb6 = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.01, max_depth = 4, random_state=42, min_child_weight = 2, subsample = 0.5)\n",
    "\n",
    "# train/fit\n",
    "xg64.fit(Xt_smote, yt_smote)\n",
    "\n",
    "# predict\n",
    "yv_pred9 = xgb6.predict(Xv_smote)\n",
    "\n",
    "# print auroc\n",
    "xgb_smote = roc_auc_score(yv_smote, yv_pred9)\n",
    "print(xgb_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fc4cf38-711e-4daa-be70-76570bec8fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using xgboost from xgboost package\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_original = xgb.XGBClassifier()\n",
    "\n",
    "xgb_original.fit(Xt_smote, yt_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b99a727-6f5a-4366-94bb-91c4dc38ba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgb_originaljoblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the original model\n",
    "from joblib import dump\n",
    "\n",
    "dump(xgb_original, 'models/xgb_original.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b17a6e7-86b7-4759-af96-df69bcde7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for training and validation sets\n",
    "y_train_preds = xgb_original.predict(Xt_smote)\n",
    "y_val_preds = xgb_original.predict(Xv_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "703c003e-35c0-4d93-b40a-90e6d7cd7451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.9800059982005398\n",
      "F1 Training: 0.979998279752876\n",
      "Accuracy Validation: 0.8893553223388306\n",
      "F1 Validation: 0.8890007206535906\n"
     ]
    }
   ],
   "source": [
    "# Display accuracy and f1 scores for base xgb\n",
    "from src.models.performance import print_class_perf\n",
    "\n",
    "print_class_perf(y_preds = y_train_preds, y_actuals = yt_smote, set_name = \"Training\", average = \"weighted\")\n",
    "print_class_perf(y_preds = y_val_preds, y_actuals = yv_smote, set_name = \"Validation\", average = \"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4810f-81af-4344-8283-dc6230870fee",
   "metadata": {},
   "source": [
    "# Import Hyperopt and perform some Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f260251-3da7-43e6-a8f2-5654a2a330b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06302d94-acab-4aa4-a0ca-f3f0a5c7ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search/grid space for XGB hyperparameters\n",
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.001, 0.01, 0.1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, .1),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fae76456-d8f9-4e66-bcba-1460e41ff292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function\n",
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree']\n",
    "    )\n",
    "    \n",
    "    acc = cross_val_score(xgboost, Xt_smote, yt_smote, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88357f16-13b5-4145-bede-448629ba0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████| 5/5 [01:12<00:00, 14.41s/trial, best loss: 0.5000499500499501]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecdfbc8a-1a14-4bd6-8c0c-d6ac80147736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.4, 'learning_rate': 0.0, 'max_depth': 1, 'min_child_weight': 9.8, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ad4f5-742d-422e-abbd-8dfd5d038439",
   "metadata": {},
   "source": [
    "# Use best set to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9653dd62-aa74-4c55-a23e-f77bc8ba7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(\n",
    "    max_depth = 4,\n",
    "    learning_rate = 0.01,\n",
    "    min_child_weight = 2,\n",
    "    subsample = 0.5,\n",
    "    colsample_bytree = 0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d188517-8326-4039-8273-6342ce85e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=4, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=4, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.4,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=4, max_leaves=0, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best.fit(Xt_smote, yt_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17d53c31-6ac5-40ed-bc6b-7862859c555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.7813655903229031\n",
      "F1 Training: 0.7813595682095444\n",
      "Accuracy Validation: 0.7718140929535232\n",
      "F1 Validation: 0.771812615777882\n"
     ]
    }
   ],
   "source": [
    "y_train_preds_best = xgb_best.predict(Xt_smote)\n",
    "y_val_preds_best = xgb_best.predict(Xv_smote)\n",
    "\n",
    "print_class_perf(y_preds = y_train_preds_best, y_actuals = yt_smote, set_name = \"Training\", average = \"weighted\")\n",
    "print_class_perf(y_preds = y_val_preds_best, y_actuals = yv_smote, set_name = \"Validation\", average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "490731f1-977a-45a8-8dc5-557afdea2d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718148816279908\n"
     ]
    }
   ],
   "source": [
    "xgb_better_roc = roc_auc_score(yv_smote, y_val_preds_best)\n",
    "print(xgb_better_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a8e432c-5ce3-422d-a734-8800a1f03a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgb_best.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(xgb_best, 'models/xgb_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "474c0125-19d4-4a84-87e5-2a35d8e1a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model on whole dataset using new hyperparameters\n",
    "# train/fit\n",
    "xgb_best.fit(X_smote, y_smote)\n",
    "\n",
    "# predict using scaled test data\n",
    "xgb_train_y_test_best= xgb_best.predict_proba(X_test)\n",
    "probabilities_best = xgb_train_y_test_best[:,1]\n",
    "\n",
    "# create a dataframe and import back the Ids into with each prediction probability\n",
    "df_xgb_best = pd.DataFrame({'Id':df_test_backup.Id, 'TARGET_5Yrs':probabilities_best})\n",
    "\n",
    "# save to CSV for upload to Kaggle without the index\n",
    "df_xgb_best.to_csv('data/external/2022_timwang_week4_try1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc9ff4-011f-480e-b63e-5f99f9c102a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
